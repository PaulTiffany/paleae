{
  "meta": {
    "tool": "paleae",
    "version": "1.0.0",
    "license": "MIT",
    "website": "https://paleae.com",
    "source": "https://github.com/PaulTiffany/paleae",
    "timestamp": "2025-09-19T21:59:02Z",
    "root_directory": "C:\\Users\\paulc\\projects\\paleae.wiki",
    "ignore_file": {
      "file": ".paleaeignore",
      "present": false,
      "patterns": 0,
      "negations": 0
    },
    "summary": {
      "total_files": 13,
      "total_chars": 45075,
      "estimated_tokens": 11264
    }
  },
  "files": [
    {
      "path": "API-Reference.md",
      "content": "# API Reference\n\nThis document provides an overview of Paleae's programmatic interface for developers who want to extend or integrate it.\n\n[< Back to Wiki Home](Home)\n\n## Programmatic Usage\nPaleae is a single-file module that can be imported directly. This allows you to integrate its file collection and snapshot generation capabilities into your own Python scripts.\n\n### Core Functions\n\n- **`collect_files()`**: The core function for gathering file paths. It uses the same powerful filtering logic as the CLI, accepting compiled regex patterns for includes, excludes, and ignore rules. See the [Configuration](Configuration) guide for more on filtering patterns.\n\n- **`build_snapshot()`**: Takes a list of file paths and constructs the main snapshot dictionary, including the `meta` and `files` sections. The structure of this dictionary is detailed in the [Output Format](Output-Format) guide.\n\n- **`write_output()`**: Writes the snapshot dictionary to a file in either `json` or `jsonl` format.\n\n- **`token_estimate()`**: A simple utility function to estimate the token count of a string using a 4-character heuristic.\n\n- **`is_text_file()`**: A helper that determines if a file should be treated as text based on its extension, size, and content (by checking for null bytes).\n\n### Example\n\n```python\nimport paleae\nfrom pathlib import Path\n\ndef create_custom_snapshot():\n    root = Path(\".\")\n    \n    # 1. Define patterns (see Configuration guide)\n    inc_patterns = paleae.compile_patterns([r\"\\.py$\", r\"\\.md$\"])\n    exc_patterns = paleae.compile_patterns([r\"test_\", r\"__pycache__\"])\n    \n    # 2. Collect files\n    # The last two arguments are for .paleaeignore patterns\n    files = paleae.collect_files(root, inc_patterns, exc_patterns, [], [])\n    \n    # 3. Build snapshot (see Output Format guide)\n    snapshot = paleae.build_snapshot(root, files, {})\n    \n    # 4. Write output\n    paleae.write_output(Path(\"custom_snapshot.json\"), snapshot, \"json\")\n    \n    print(f\"Successfully created snapshot with {len(files)} files.\")\n\nif __name__ == \"__main__\":\n    create_custom_snapshot()\n```\n\nFor more complex examples, such as integrating with Git or creating custom reports, see the [Advanced Usage](Advanced-Usage) guide.\n\n---\n*Paleae is a Python tool for creating clean codebase snapshots for LLM context, analysis, and reporting.*",
      "size_chars": 2337,
      "sha256": "80b45e9feb1bba66370bf2ed63ff373b11c996da2e346c7c161b727455c3d992",
      "estimated_tokens": 584
    },
    {
      "path": "Advanced-Usage.md",
      "content": "# Advanced Usage\n\nThis page covers power-user workflows and advanced integration patterns for Paleae.\n\n[< Back to Wiki Home](Home)\n\n## Workflow Automation\n\n### GitHub Actions\nYou can automate snapshot creation on every push using a GitHub Actions workflow. This is a key feature discussed in the [Integration Guide](Integration-Guide).\n\n```yaml\n# .github/workflows/snapshot.yml\nname: Create Code Snapshot\non: [push]\njobs:\n  snapshot:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - uses: actions/setup-python@v4\n    - name: Download and Run Paleae\n      run: |\n        curl -fsSL https://raw.githubusercontent.com/PaulTiffany/paleae/main/paleae.py -o paleae.py\n        python paleae.py --profile ai_optimized -f jsonl -o snapshot.jsonl\n    - uses: actions/upload-artifact@v3\n      with:\n        name: code-snapshot\n        path: snapshot.jsonl\n```\n\n### Pre-commit Hook\nAutomatically create a snapshot before each commit to track changes. This pattern is also covered in the [Integration Guide](Integration-Guide).\n```bash\n#!/bin/sh\n# .git/hooks/pre-commit\npython paleae.py --profile ai_optimized -o .git/snapshot_$(date +%Y%m%d).json\n```\n\n## Large Repository Strategies\n\n### Chunked Processing\nFor massive repositories, process different parts separately and combine them later. This is a useful technique for managing memory, as noted in the [FAQ](FAQ).\n```bash\npython paleae.py --include \"^src/core/\" -f jsonl -o core.jsonl\npython paleae.py --include \"^src/utils/\" -f jsonl -o utils.jsonl\n```\n\n### Selective Scanning\nFocus only on recently changed files to speed up processing.\n```bash\n# Get files changed in the last 7 days and create a snapshot\nRECENT_FILES=$(git log --since=\"7 days ago\" --name-only --pretty=format: | sort -u)\npython paleae.py --include \"($(echo $RECENT_FILES | tr ' ' '|'))\" -o recent.json\n```\n\n---\n*Paleae is a Python tool for creating clean codebase snapshots for LLM context, analysis, and reporting.*",
      "size_chars": 1956,
      "sha256": "da81a020881d12dee5b8b48b1118644f2b9ea409527ce2932e78ca2821c1d611",
      "estimated_tokens": 489
    },
    {
      "path": "Configuration.md",
      "content": "# Configuration\n\nPaleae uses a powerful filtering system to give you precise control over your snapshots. This guide covers the `.paleaeignore` file, command-line profiles, and custom regex patterns.\n\n## Table of Contents\n- [Quick Reference](#quick-reference)\n- [The .paleaeignore File](#the-paleaeignore-file)\n- [Command-Line Profiles](#command-line-profiles)\n- [Custom Regex Patterns](#custom-regex-patterns)\n- [Filter Priority](#filter-priority)\n\n---\n\n## Quick Reference\n\n| Method | How it Works | Best For |\n| :--- | :--- | :--- |\n| **Profiles** | Broad, predefined sets of rules (`minimal`, `ai_optimized`). | Quick, common use cases. |\n| **`.paleaeignore`** | A file in your repo with `.gitignore`-style rules. | Project-specific, version-controlled ignore rules. |\n| **`--include/--exclude`** | Command-line regex for one-off, specific filtering. | Dynamic or temporary filtering needs. |\n\n---\n\n## The .paleaeignore File\n\nFor project-specific rules that you want to save and version control, create a `.paleaeignore` file in your root directory. The syntax is the same as `.gitignore`.\n\n### Basic Exclusions\nEach line specifies a pattern to exclude.\n```\n# Comments are ignored\n*.log\nbuild/\ndist/\n*.tmp\n```\n\n### Negation (Force Include)\nYou can force-include a file that would otherwise be ignored by prefixing the pattern with `!`. This is useful for making exceptions to broad rules.\n\n```\n# Ignore all config files...\n*.toml\n*.json\n\n# ...but always include these critical ones.\n!pyproject.toml\n!package.json\n```\n\n---\n\n## Command-Line Profiles\n\nProfiles are quick ways to apply a smart set of filtering rules, passed via the `--profile` flag in the [Usage Guide](Usage-Guide).\n\n`--profile minimal` (Default)\n- **What it does**: Includes most text files but excludes common patterns like `.git/`, `__pycache__/`, `node_modules/`, and build artifacts.\n- **Use it for**: General-purpose snapshots, backups, or when you want a comprehensive view of the project.\n\n`--profile ai_optimized`\n- **What it does**: A stricter profile that focuses on core source code (`src/`, `tests/`) and essential project metadata (`pyproject.toml`, `README.md`).\n- **Use it for**: Creating clean, focused snapshots specifically for analysis by an AI or LLM.\n\n---\n\n## Custom Regex Patterns\n\nFor maximum control, you can provide your own regex patterns on the command line. See the [Usage Guide](Usage-Guide) for command-line examples.\n\n`--include <REGEX>`\n- **Description**: Only include files whose paths match the regex. Can be used multiple times.\n- **Example**: To snapshot only your `pyproject.toml` and files in the `src` directory:\n  ```bash\n  python3 paleae.py --include \"^pyproject\\.toml$\" --include \"^src/\"\n  ```\n\n`--exclude <REGEX>`\n- **Description**: Exclude any files whose paths match the regex.\n- **Example**: To exclude all test files and any files in a `data` directory:\n  ```bash\n  python3 paleae.py --exclude \"_test\\.py$\" --exclude \"^data/\"\n  ```\n\n---\n\n## Filter Priority\n\nPaleae applies filters in a specific, layered order. This diagram shows how files flow through the process, with each step filtering the set of files from the previous one.\n\n```mermaid\ngraph TD\n    A[All Project Files] --> F1;\n    subgraph Filtering Pipeline\n        direction TB\n        F1(1. Default Exclusions) --> F2(2. --exclude Patterns);\n        F2 --> F3(3. .paleaeignore Patterns);\n        F3 --> F4(4. .paleaeignore Negations !);\n        F4 --> F5(5. --include / Profile Patterns);\n    end\n    F5 --> B[Files in Snapshot];\n\n    style F1 fill:#ffe4e1,stroke:#333\n    style F2 fill:#ffe4e1,stroke:#333\n    style F3 fill:#ffe4e1,stroke:#333\n    style F4 fill:#e6e6fa,stroke:#333\n    style F5 fill:#d4edda,stroke:#333\n```\n\n1.  **Default Exclusions**: The built-in patterns (like `.git/`) are applied first to remove common noise.\n2.  **`--exclude` Patterns**: Your custom command-line exclusions are applied next.\n3.  **`.paleaeignore` Patterns**: All exclusion patterns from your `.paleaeignore` file are applied.\n4.  **`.paleaeignore` Negations**: Any `!` patterns in your `.paleaeignore` file are applied, overriding any previous exclusions to bring files back into consideration.\n5.  **`--include` / Profile Patterns**: Finally, if `--include` patterns are provided, only files that have survived the exclusion steps *and* match an include pattern are kept. If no `--include` patterns are given, the active profile's include rules are used instead.\n\n---\n*Paleae is a Python tool for creating clean codebase snapshots for LLM context, analysis, and reporting.*\n",
      "size_chars": 4544,
      "sha256": "3c3a055594118662f5efb44db731d340c7d3654f25bbcebbb3510a04d4366eb6",
      "estimated_tokens": 1136
    },
    {
      "path": "Cookbook.md",
      "content": "# Paleae Cookbook\n\nThis page provides practical, copy-paste-ready recipes for common Paleae workflows.\n\n[< Back to Wiki Home](Home)\n\n## Table of Contents\n- [Snapshot Recently Changed Files](#snapshot-recently-changed-files)\n- [Compare Two Snapshots](#compare-two-snapshots)\n- [Generate a Codebase Report](#generate-a-codebase-report)\n- [Filter Snapshot for a Token Budget](#filter-snapshot-for-a-token-budget)\n\n---\n\n## Snapshot Recently Changed Files\n\n**Goal:** Create a snapshot containing only the files that have been modified in the last 7 days.\n\n**Use Case:** Quickly providing context to an AI about recent development activity without including the entire codebase.\n\n**Method:** This shell script uses `git log` to find the files and pipes them into Paleae's `--include` filter.\n\n```bash\n#!/bin/bash\n# recent_changes.sh\n\n# 1. Get a list of files changed in the last 7 days, separated by |\nRECENT_FILES=$(git log --since=\"7 days ago\" --name-only --pretty=format: | sort -u | tr '\\n' '|')\n\n# 2. Remove the trailing | if the list is not empty\nif [ -n \"$RECENT_FILES\" ]; then\n    PATTERN=\"(${RECENT_FILES%|})\"\n    \n    # 3. Create the snapshot using the generated pattern\n    python3 paleae.py --include \"$PATTERN\" -o recent_changes.json\n    \n    echo \"Snapshot of recently changed files created in recent_changes.json\"\nelse\n    echo \"No recent changes found.\"\nfi\n```\n\n---\n\n## Compare Two Snapshots\n\n**Goal:** Identify the differences between two snapshot files.\n\n**Use Case:** Understanding what has changed between two points in time, such as before and after a major refactoring.\n\n**Method:** This Python script loads two snapshot files and compares the file paths and their SHA-256 hashes.\n\n```python\n#!/usr/bin/env python3\n# compare_snapshots.py\n\nimport json\nimport sys\n\ndef compare_snapshots(old_path, new_path):\n    \"\"\"Compare two snapshots and print a summary of changes.\"\"\"\n    \n    with open(old_path) as f:\n        old_data = json.load(f)\n    with open(new_path) as f:\n        new_data = json.load(f)\n    \n    old_files = {f[\"path\"]: f[\"sha256\"] for f in old_data[\"files\"]}\n    new_files = {f[\"path\"]: f[\"sha256\"] for f in new_data[\"files\"]}\n    \n    added = set(new_files.keys()) - set(old_files.keys())\n    removed = set(old_files.keys()) - set(new_files.keys())\n    \n    modified = {\n        path for path in old_files.keys() & new_files.keys() \n        if old_files[path] != new_files[path]\n    }\n    \n    print(f\"--- Snapshot Comparison ---\")\n    print(f\"Old: {old_path} ({old_data['meta']['summary']['total_files']} files)\")\n    print(f\"New: {new_path} ({new_data['meta']['summary']['total_files']} files)\")\n    print(\"---------------------------\")\n    print(f\"Added:    {len(added)}\")\n    print(f\"Removed:  {len(removed)}\")\n    print(f\"Modified: {len(modified)}\")\n\n    if added:\n        print(\"\\n--- Added Files ---\")\n        for path in sorted(added):\n            print(f\"+ {path}\")\n\n    if modified:\n        print(\"\\n--- Modified Files ---\")\n        for path in sorted(modified):\n            print(f\"~ {path}\")\n\nif __name__ == \"__main__\":\n    if len(sys.argv) != 3:\n        print(\"Usage: python3 compare_snapshots.py <old_snapshot.json> <new_snapshot.json>\")\n        sys.exit(1)\n    \n    compare_snapshots(sys.argv[1], sys.argv[2])\n```\n\n---\n\n## Generate a Codebase Report\n\n**Goal:** Create a high-level Markdown report from a snapshot.\n\n**Use Case:** Generating quick, shareable documentation about the project's structure and composition.\n\n**Method:** This Python script processes a snapshot file and prints a Markdown-formatted report to the console.\n\n```python\n#!/usr/bin/env python3\n# generate_report.py\n\nimport json\nfrom collections import defaultdict\nimport sys\n\ndef generate_report(snapshot_path):\n    \"\"\"Analyzes a snapshot and prints a Markdown report.\"\"\"\n    with open(snapshot_path) as f:\n        data = json.load(f)\n\n    by_ext = defaultdict(lambda: {'count': 0, 'chars': 0})\n    for file_obj in data['files']:\n        ext = '.' + file_obj['path'].split('.')[-1] if '.' in file_obj['path'] else 'no_extension'\n        by_ext[ext]['count'] += 1\n        by_ext[ext]['chars'] += file_obj['size_chars']\n\n    print(f\"# Codebase Report for {data['meta']['root_directory']}\")\n    print(f\"_Generated on {data['meta']['timestamp']}_\")\n    print(\"\\n## Summary\")\n    print(f\"- **Total Files:** {data['meta']['summary']['total_files']}\")\n    print(f\"- **Total Characters:** {data['meta']['summary']['total_chars']:,}\")\n    print(f\"- **Estimated Tokens:** {data['meta']['summary']['estimated_tokens']:,}\")\n\n    print(\"\\n## File Types\")\n    print(\"| Extension | File Count | Total Chars |\")\n    print(\"| :--- | :--- | :--- |\")\n    for ext, stats in sorted(by_ext.items(), key=lambda x: x[1]['count'], reverse=True):\n        print(f\"| {ext} | {stats['count']} | {stats['chars']:,} |\")\n\nif __name__ == \"__main__\":\n    if len(sys.argv) != 2:\n        print(\"Usage: python3 generate_report.py <snapshot.json>\")\n        sys.exit(1)\n\n    generate_report(sys.argv[1])\n```\n\n---\n\n## Filter Snapshot for a Token Budget\n\n**Goal:** Reduce a snapshot's size to fit within an LLM's context window.\n\n**Use Case:** Ensuring your snapshot doesn't exceed the token limit of models like GPT-4 (e.g., 128k tokens) or Claude 3 (e.g., 200k tokens).\n\n**Method:** This Python script loads a snapshot, removes files until it fits the budget, prioritizing source code over other file types.\n\n```python\n#!/usr/bin/env python3\n# filter_by_tokens.py\n\nimport json\nimport sys\n\ndef filter_for_budget(snapshot_path, max_tokens=100000):\n    \"\"\"Filters a snapshot to fit within a specified token budget.\"\"\"\n    with open(snapshot_path) as f:\n        data = json.load(f)\n\n    if data['meta']['summary']['estimated_tokens'] <= max_tokens:\n        print(\"Snapshot is already within the token budget.\")\n        return\n\n    # Prioritize file types (e.g., source code > docs > configs)\n    priority_exts = ['.py', '.js', '.ts', '.go', '.rs', '.java', '.md', '.toml', '.yaml']\n    \n    # Sort files by priority and then by size (smallest first)\n    def sort_key(file_obj):\n        ext = '.' + file_obj['path'].split('.')[-1] if '.' in file_obj['path'] else ''\n        priority = priority_exts.index(ext) if ext in priority_exts else len(priority_exts)\n        return (priority, file_obj['estimated_tokens'])\n\n    sorted_files = sorted(data['files'], key=sort_key)\n\n    # Fill the budget with the highest priority files\n    selected_files = []\n    token_count = 0\n    for file_obj in sorted_files:\n        if token_count + file_obj['estimated_tokens'] <= max_tokens:\n            selected_files.append(file_obj)\n            token_count += file_obj['estimated_tokens']\n\n    # Create the new, smaller snapshot\n    data['files'] = selected_files\n    data['meta']['summary']['total_files'] = len(selected_files)\n    data['meta']['summary']['total_chars'] = sum(f['size_chars'] for f in selected_files)\n    data['meta']['summary']['estimated_tokens'] = token_count\n\n    output_path = snapshot_path.replace('.json', '_filtered.json')\n    with open(output_path, 'w') as f:\n        json.dump(data, f, indent=2)\n    \n    print(f\"Filtered snapshot saved to {output_path}\")\n    print(f\"New token count: {token_count:,} / {max_tokens:,}\")\n\nif __name__ == \"__main__\":\n    if len(sys.argv) != 3:\n        print(\"Usage: python3 filter_by_tokens.py <snapshot.json> <max_tokens>\")\n        sys.exit(1)\n\n    filter_for_budget(sys.argv[1], int(sys.argv[2]))\n```\n\n---\n*Paleae is a Python tool for creating clean codebase snapshots for LLM context, analysis, and reporting.*",
      "size_chars": 7527,
      "sha256": "0cd68895bd8f09c24245eb2a402e56113143a52479acf96729be29517e2339b9",
      "estimated_tokens": 1881
    },
    {
      "path": "FAQ.md",
      "content": "# Paleae Frequently Asked Questions (FAQ)\n\nCommon questions and answers about using Paleae to create Python code snapshots for AI analysis and LLM context management.\n\n## General\n\n### What is Paleae used for?\nPaleae is a single-file, zero-dependency Python tool that creates structured JSON or JSONL snapshots of a codebase. Its main use is to prepare code for analysis by Large Language Models (LLMs) by creating a clean, context-rich representation of a repository.\n\n### How is Paleae different from `zip` or `tar`?\nWhile tools like `zip` just archive files, Paleae is designed to intelligently prepare your code for analysis. It filters out irrelevant files, includes essential metadata, and produces a clean, machine-readable [JSON or JSONL output](Output-Format) perfect for scripting and AI context windows.\n\n## Installation\n\n### How do I install Paleae?\nThere is no installation. Paleae is a single Python file. For a complete walkthrough, see the [Getting Started](Getting-Started) guide.\n\n## Usage\n\n### How can I control which files are in the snapshot?\nPaleae offers powerful filtering options. You can use a `.paleaeignore` file for project-specific rules or use command-line flags like `--include` and `--exclude` for ad-hoc filtering. Both methods are covered in the [Configuration guide](Configuration).\n\n### What is the difference between JSON and JSONL output?\n- **JSON**: A single, human-readable file. Best for smaller projects.\n- **JSONL**: A stream of JSON objects, one per line. Best for very large projects as it is more memory-efficient.\n\nSee the [Output Format documentation](Output-Format) for a detailed comparison.\n\n### How can I manage the snapshot size for an LLM context window?\nThe estimated token count in the metadata helps you gauge the size. For practical examples of how to reduce the snapshot size to fit a specific token budget, see the recipes in our [Cookbook](Cookbook).\n\n## Technical\n\n### Why are some of my files missing from the snapshot?\nThis is usually due to filtering. Paleae skips files that are over 10MB, binary files, or files that match an exclusion pattern. For a full checklist, see the [Troubleshooting guide](Troubleshooting).\n\n### Can I use Paleae as part of a script?\nYes. Paleae can be imported as a standard Python module. The [API Reference](API-Reference) provides complete documentation for programmatic usage.\n\n---\n*Paleae is a Python tool for creating clean codebase snapshots for LLM context, analysis, and reporting.*",
      "size_chars": 2485,
      "sha256": "0abcc4fa39b21524214169d049a54c483af1c6dde73c93666f348926b146776e",
      "estimated_tokens": 621
    },
    {
      "path": "Getting-Started.md",
      "content": "# Getting Started with Paleae\n\nThis guide covers the simple steps to download and run Paleae on your system. Because it's a single, dependency-free Python script, no installation is required.\n\n## Visual Quickstart\n\n```mermaid\ngraph LR\n    A[\"<b>Step 1</b><br>Download Script\"] --> B[\"<b>Step 2</b><br>Run Paleae\"];\n    B --> C[\"<b>Step 3</b><br>Get Snapshot\"];\n```\n\n---\n\n## 1. Download the Script\n\nYou can download the `paleae.py` script using the command line tools below. To download it in your browser, **right-click this link and select \"Save Link As...\"**: [paleae.py](https://raw.githubusercontent.com/PaulTiffany/paleae/main/paleae.py)\n\n### macOS / Linux\n```bash\ncurl -fsSL https://raw.githubusercontent.com/PaulTiffany/paleae/main/paleae.py -o paleae.py\n```\n\n### Windows (PowerShell)\n```powershell\nInvoke-WebRequest -Uri https://raw.githubusercontent.com/PaulTiffany/paleae/main/paleae.py -OutFile paleae.py\n```\n\n## 2. Run Paleae\n\nNavigate your terminal to the root directory of the project you want to snapshot, then execute the script.\n\n```bash\n# It's recommended to use python3 to ensure a modern version\npython3 paleae.py\n```\n\n## 3. Check the Output\n\nBy default, Paleae will create a file named `repo_snapshot.json` in the directory where you ran the command. This single file contains the complete snapshot of all discovered text files in your project.\n\nCongratulations, you've created your first snapshot!\n\n---\n\n## What's Next?\n\n- **[Usage Guide](Usage-Guide)**: Learn about all the available command-line options.\n- **[Configuration](Configuration)**: Discover how to use a `.paleaeignore` file to control which files are included.\n- **[Advanced Usage](Advanced-Usage)**: See how to use profiles and other features for specialized workflows.\n\n## Getting Help\n\n- Run `python paleae.py --help` for command-line options.\n- Check the [Troubleshooting](Troubleshooting) guide for common issues.\n\n---\n*Paleae is a Python tool for creating clean codebase snapshots for LLM context, analysis, and reporting.*\n",
      "size_chars": 2016,
      "sha256": "0cb0af642b28589c02703903ac6e06a22f9389054f41649daa0071812e7f25b9",
      "estimated_tokens": 504
    },
    {
      "path": "Home.md",
      "content": "# Welcome to the Paleae Wiki\n\nPaleae is a single-file, zero-dependency Python tool that creates structured JSON/JSONL snapshots of your codebase. It is the ideal tool to prepare a codebase for analysis by Large Language Models (LLMs), manage LLM context windows, or for any task that requires a clean, machine-readable representation of your code.\n\nThis wiki provides comprehensive documentation for Paleae's features, configuration, and use cases, helping you create the perfect Python code snapshot.\n\n## Quick Navigation\n\n- [Getting Started](Getting-Started) - Installation and your first snapshot.\n- [Cookbook](Cookbook) - Practical recipes and examples.\n- [Usage Guide](Usage-Guide) - All command-line options and examples.\n- [Configuration](Configuration) - Using `.paleaeignore` and profiles to customize your snapshot.\n- [Output Format](Output-Format) - A detailed look at the JSON/JSONL structure.\n- [Philosophy](Philosophy) - The design principles and vision behind the project.\n- [API Reference](API-Reference) - For programmatic usage.\n\n---\n\n## Key Features\n\n- **Single File, Zero Dependencies**: `paleae.py` is a self-contained script. Drop it into any project and run it with a standard Python 3 interpreter.\n- **Local-First and Private**: Paleae runs entirely on your machine. It makes no network calls and sends no telemetry. Your code remains private, always.\n- **AI-Optimized Output**: The output is clean, structured JSON or JSONL, designed for easy parsing by AI models.\n- **Powerful Filtering**: Customize your snapshots with a `.paleaeignore` file that uses familiar `.gitignore` syntax, including negations (`!`).\n- **Reliable and Deterministic**: With a comprehensive test suite, Paleae provides predictable, deterministic output.\n\n---\n\n## Quick Example\n\nRun Paleae in your project directory:\n```bash\n# Download the script\ncurl -fsSL https://raw.githubusercontent.com/PaulTiffany/paleae/main/paleae.py -o paleae.py\n\n# Run it\npython3 paleae.py\n```\n\nThis creates a `repo_snapshot.json` file that looks like this (simplified):\n```json\n{\n  \"meta\": {\n    \"tool\": \"paleae\",\n    \"version\": \"1.0.0\",\n    \"summary\": {\n      \"total_files\": 5,\n      \"estimated_tokens\": 2560\n    }\n  },\n  \"files\": [\n    {\n      \"path\": \"src/main.py\",\n      \"content\": \"def hello():\\n    print(\\\"Hello, World!\\\")\\n\",\n      \"sha256\": \"...\"\n    }\n  ]\n}\n```\n\n## Support\n\n- Report bugs and request features on [GitHub Issues](https://github.com/PaulTiffany/paleae/issues).\n- Ask questions and share ideas in [GitHub Discussions](https://github.com/PaulTiffany/paleae/discussions).\n\n---\n*Paleae is a Python tool for creating clean codebase snapshots for LLM context, analysis, and reporting.*\n",
      "size_chars": 2682,
      "sha256": "a372267eb2f8d763ed32842b60ebfecddf24935187a71d85a8387ed7618ef568",
      "estimated_tokens": 670
    },
    {
      "path": "Integration-Guide.md",
      "content": "# Integrating Paleae with Developer Tools\n\nThis guide explains how Paleae complements your existing development workflow. Instead of replacing tools like Git, `ripgrep`, or CI/CD systems, Paleae enhances them by providing a clean, structured, and AI-ready **Python code snapshot** for analysis and reporting.\n\n[< Back to Wiki Home](Home)\n\n## Table of Contents\n\n- [Version Control (Git)](#version-control-systems)\n- [Archive Tools (zip, tar)](#archive-tools)\n- [Text Search (ripgrep)](#text-processing-tools)\n- [CI/CD Pipelines (GitHub Actions)](#cicd-pipelines)\n\n---\n\n## Version Control Systems\n\n### Git, Mercurial, SVN\n\n- **What they do:** Track code history and manage collaboration.\n- **What Paleae adds:** Creates point-in-time, [AI-ready snapshots](Output-Format) of your codebase, perfect for analyzing changes or providing context to an LLM.\n\n**Integration Strategy:** Use Git hooks to automatically generate a snapshot on each commit. See the [Cookbook](Cookbook) for practical script examples.\n\n---\n\n## Archive Tools\n\n### zip, tar, 7z\n\n- **What they do:** Compress and bundle files.\n- **What Paleae adds:** Intelligently [filters content](Configuration) and adds [structured metadata](Output-Format) to create a machine-readable snapshot, not just a dumb archive.\n\n**Integration Strategy:** When creating a release, generate both a `.zip` archive for users and a Paleae snapshot for automated analysis and bill-of-materials reporting.\n\n---\n\n## Text Processing Tools\n\n### grep, ripgrep, ag\n\n- **What they do:** Find specific lines of text in files.\n- **What Paleae adds:** Provides the full, structured context of the entire codebase, which is essential for effective LLM analysis.\n\n**Integration Strategy:** Use a fast search tool like `ripgrep` to find a list of relevant files, then pipe that list to Paleae to create a highly focused snapshot for debugging or review.\n\n---\n\n## CI/CD Pipelines\n\n### GitHub Actions, Jenkins, GitLab CI\n\n- **What they do:** Automate the build, test, and deployment process.\n- **What Paleae adds:** A reliable way to generate a consistent **codebase snapshot** for analysis at any stage of the pipeline.\n\n**Integration Strategy:** Add a step in your CI pipeline to generate a snapshot using the [`--profile ai_optimized`](Configuration). This snapshot can then be passed to a security scanner, a code reviewer AI, or archived as a build artifact. See the [Advanced Usage](Advanced-Usage) guide for a complete GitHub Actions example.\n\n---\n*Paleae is a Python tool for creating clean codebase snapshots for LLM context, analysis, and reporting.*\n",
      "size_chars": 2585,
      "sha256": "cc2491421f2827e5e8c8a7db2d1118fe4bde93acd4ed665629dc7512f9306261",
      "estimated_tokens": 646
    },
    {
      "path": "Output-Format.md",
      "content": "# Output Format\n\nPaleae generates structured output in JSON or JSONL format, optimized for AI analysis and programmatic processing.\n\n## Format Overview\n\n### JSON Format (Default)\nA single JSON object containing metadata and a list of all files.\n```json\n{\n  \"meta\": { ... },\n  \"files\": [ ... ]\n}\n```\n**Best for**: Small to medium repositories, human inspection, and tools that require a complete JSON object.\n\n### JSONL Format\nLine-delimited JSON, with one object per line.\n```jsonl\n{\"type\":\"meta\",\"tool\":\"paleae\",...}\n{\"type\":\"file\",\"path\":\"src/main.py\",...}\n{\"type\":\"file\",\"path\":\"README.md\",...}\n```\n**Best for**: Large repositories, streaming processing, and memory efficiency. See [Advanced Usage](Advanced-Usage) for examples.\n\n---\n\n## Metadata Structure (`meta`)\n\n| Field | Type | Description |\n| :--- | :--- | :--- |\n| `tool` | string | Always \"paleae\". |\n| `version` | string | The version of Paleae used. |\n| `timestamp` | string | ISO 8601 UTC timestamp of generation. |\n| `root_directory` | string | Absolute path to the scanned directory. |\n| `ignore_file` | object | Information about the `.paleaeignore` file. See [Configuration](Configuration). |\n| `summary` | object | Aggregate statistics for the snapshot. |\n\n---\n\n## File Object Structure (`files`)\n\n| Field | Type | Description |\n| :--- | :--- | :--- |\n| `path` | string | The relative path to the file from the root. |\n| `content` | string | The full content of the file. |\n| `size_chars` | integer | The number of characters in the file. |\n| `sha256` | string | A SHA-256 hash of the file content for integrity checks. |\n| `estimated_tokens` | integer | An approximate token count (based on character count). |\n\n### Path Normalization\n- Paths always use forward slashes (`/`).\n- Paths are relative to the repository root (e.g., `src/main.py`).\n\n### Hash Verification\nThe SHA-256 hash allows you to verify content integrity and detect changes between snapshots, as mentioned in the [FAQ](FAQ).\n\n---\n*Paleae is a Python tool for creating clean codebase snapshots for LLM context, analysis, and reporting.*",
      "size_chars": 2074,
      "sha256": "009df6afe417ae69baeedbcb257744703bf7f5760b4e12069869d50dbff50a16",
      "estimated_tokens": 518
    },
    {
      "path": "Philosophy.md",
      "content": "# Philosophy\n\nThe design and development of Paleae are guided by a few core principles.\n\n[< Back to Wiki Home](Home)\n\n## Core Principles\n\n- **Simplicity and Trust**: Paleae is a single, dependency-free Python script. Its simplicity makes it easy to understand, audit, and trust. What you see is what you get.\n\n- **Local-First and Private**: Your code is your own. Paleae runs entirely on your machine, makes no network calls, and sends no telemetry. It is designed to be a safe, offline-first tool.\n\n- **Deterministic and Reliable**: Given the same input, Paleae will always produce the same output. File content is hashed with SHA-256, ensuring that snapshots are verifiable and can be trusted in automated workflows. This is detailed in the [Output Format](Output-Format) guide.\n\n- **User Intent is Paramount**: The tool provides clear and powerful filtering through `.paleaeignore` files (with negation) and command-line patterns. You have explicit control over what goes into a snapshot, as explained in the [Configuration](Configuration) guide.\n\n- **Minimalism over Feature Creep**: Every feature is weighed against the cost of added complexity. The goal is to do one thing and do it well: create clean, structured codebase snapshots.\n\n---\n*Paleae is a Python tool for creating clean codebase snapshots for LLM context, analysis, and reporting.*\n",
      "size_chars": 1351,
      "sha256": "de64fac05d80359f3d25096144e81bce64d037d0f594dd81822cafcc020443f9",
      "estimated_tokens": 337
    },
    {
      "path": "Troubleshooting.md",
      "content": "# Troubleshooting\n\nCommon issues and solutions for Paleae.\n\n[< Back to Wiki Home](Home)\n\n## \"No text files found matching criteria\"\n\nThis is the most common issue and usually means your filtering is too restrictive.\n\n- **Check your directory**: Make sure you are running Paleae in a directory that actually contains code.\n- **Test with a broad pattern**: Try `python paleae.py --include \".*\"`. See the [Usage Guide](Usage-Guide) for more on patterns.\n- **Check your `.paleaeignore`**: You may have a pattern (e.g., `src/`) that is excluding everything. See the [Configuration](Configuration) guide.\n- **Check file sizes**: Files over 10MB are skipped by default.\n\n## \"Invalid regex\"\n\nThis error means the pattern you provided to `--include` or `--exclude` is not a valid regular expression.\n\n- **Remember to escape special characters**: For example, to match a literal dot, you must use `\\.`. The [Configuration](Configuration) guide has a section on regex patterns.\n- **Example**: To match all Python files, use `\\.py$` not `*.py`. The latter is a glob pattern, not a regex.\n\n## Out of Memory Errors\n\nIf Paleae crashes on a large repository, you are likely running out of RAM.\n\n- **Use JSONL format**: This streams the output and uses significantly less memory, as explained in the [Output Format](Output-Format) guide.\n  ```bash\n  python paleae.py -f jsonl -o my_snapshot.jsonl\n  ```\n- **Be more selective**: Use filters to reduce the number of files included in the snapshot.\n\n## `.paleaeignore` Not Working\n\n- **Check the file location**: It must be in the same directory where you are running the `paleae` command.\n- **Check the syntax**: `.paleaeignore` uses **glob** patterns (like `.gitignore`), not regex. This is a common mistake. See the [Configuration](Configuration) guide for examples.\n\n---\n*Paleae is a Python tool for creating clean codebase snapshots for LLM context, analysis, and reporting.*",
      "size_chars": 1910,
      "sha256": "6fdc3b3ad215e39295e68b1341636d76c5df52bbc867d238973c4f8d5362a10f",
      "estimated_tokens": 477
    },
    {
      "path": "Usage-Guide.md",
      "content": "# Usage Guide\n\nThis guide covers all command-line options for Paleae.\n\n[< Back to Wiki Home](Home)\n\n## Command Syntax\n```bash\npython paleae.py [directory] [options]\n```\n\n## Basic Options\n\n- **`directory`**: The directory to snapshot. Defaults to the current directory.\n- **`-o, --out`**: Specify the output file name. Defaults to `repo_snapshot.json`.\n- **`-f, --format`**: The output format. Can be `json` (default) or `jsonl`. See the [Output Format](Output-Format) guide for details on the structure.\n\n## Filtering Options\n\n- **`--profile`**: Use a built-in filtering profile. See the [Configuration](Configuration) guide for a full explanation of profiles.\n  - `minimal`: Includes most text files but skips common artifacts.\n  - `ai_optimized`: Focuses on source code and key documentation for AI analysis.\n- **`--include`**: A regex pattern to **include** files. Can be used multiple times.\n- **`--exclude`**: A regex pattern to **exclude** files. Can be used multiple times.\n\nFor a detailed guide on how these filters work together, see the [Configuration](Configuration) page.\n\n## Common Workflows\n\n### AI Code Analysis\nCreate a clean, focused snapshot for analysis by an LLM.\n```bash\npython paleae.py --profile ai_optimized -o for_ai.json\n```\n\n### Documentation Generation\nSnapshot only documentation and configuration files.\n```bash\npython paleae.py --include \"\\.(md|rst|toml|yaml)$\" -o docs_and_config.json\n```\n\n### Large Repositories\nUse JSONL format and selective filtering for better performance on large codebases, as discussed in [Advanced Usage](Advanced-Usage).\n```bash\npython paleae.py -f jsonl --include \"^src/core/\" -o large_repo_core.jsonl\n```\n\n---\n*Paleae is a Python tool for creating clean codebase snapshots for LLM context, analysis, and reporting.*",
      "size_chars": 1775,
      "sha256": "80f2435cccfec33d367f46db05c1ea6fd7e4fcf508f554885312aadb29184f09",
      "estimated_tokens": 443
    },
    {
      "path": "paleae.py",
      "content": "#!/usr/bin/env python3\n# SPDX-License-Identifier: MIT\n# Copyright (c) 2025 Paul Tiffany\n# Project: paleae - Snapshot your repo for LLMs\n# Website: https://paleae.com\n# Source:  https://github.com/PaulTiffany/paleae\n\n\"\"\"\npaleae - Create JSON/JSONL snapshots of your repository for LLMs.\n\nA single-file, zero-dependency tool that scans your codebase and creates\nstructured snapshots optimized for AI analysis and processing.\n\"\"\"\n\nimport argparse\nimport fnmatch\nimport hashlib\nimport json\nimport re\nimport sys\nimport time\nfrom pathlib import Path\nfrom typing import Any, Optional\n\n# Project metadata (also embedded in output)\n__version__ = \"1.0.0\"\n__license__ = \"MIT\"\n__website__ = \"https://paleae.com\"\n__source__ = \"https://github.com/PaulTiffany/paleae\"\n\n# --- Configuration ---\nMAX_SIZE = 10 * 1024 * 1024  # 10MB\nPALEAEIGNORE = \".paleaeignore\"\n\nTEXT_EXTS = {\n    \".py\",\n    \".md\",\n    \".rst\",\n    \".txt\",\n    \".json\",\n    \".yaml\",\n    \".yml\",\n    \".toml\",\n    \".ini\",\n    \".cfg\",\n    \".xml\",\n    \".csv\",\n    \".tsv\",\n    \".html\",\n    \".css\",\n    \".js\",\n    \".ts\",\n    \".tsx\",\n    \".c\",\n    \".h\",\n    \".cpp\",\n    \".hpp\",\n    \".java\",\n    \".kt\",\n    \".go\",\n    \".rs\",\n    \".rb\",\n    \".php\",\n    \".sh\",\n    \".ps1\",\n}\n\nDEFAULT_SKIP = [\n    r\"(^|/)\\.(git|hg|svn)($|/)\",\n    r\"(^|/)__pycache__($|/)\",\n    r\"(^|/)\\.(pytest|mypy|ruff)_cache($|/)\",\n    r\"(^|/)(\\.?venv|env)($|/)\",\n    r\"(^|/)node_modules($|/)\",\n    r\"(^|/)(build|dist)($|/)\",\n    r\"(^|/)coverage($|/)\",\n    r\"(^|/)htmlcov($|/)\",\n    r\"(^|/)\\.coverage($|/)?\",\n    r\"(^|/)\\.env($|/)\",\n    r\"(^|/)\" + re.escape(PALEAEIGNORE) + r\"($|/)?\",  # Ignore our own config file\n]\n\nPROFILES = {\n    \"minimal\": {\"include\": [r\".*\"], \"exclude\": DEFAULT_SKIP},\n    \"ai_optimized\": {\n        \"include\": [\n            r\"^(src|tests)(/.*)?$\",\n            r\"^pyproject\\.toml$\",\n            r\"^README(\\.md|\\.rst)?$\",\n            r\"^(ROADMAP|CHANGELOG)\\.md$\",\n        ],\n        \"exclude\": DEFAULT_SKIP + [r\"(^|/)docs/\"],\n    },\n}\n\n# --- Core Logic ---\n\n\nclass PaleaeError(Exception):\n    \"\"\"Base exception for paleae operations.\"\"\"\n\n\ndef token_estimate(text: str) -> int:\n    \"\"\"Estimate tokens using 4-char heuristic.\"\"\"\n    return max(1, len(text) // 4) if text else 0\n\n\ndef is_text_file(path: Path) -> bool:\n    \"\"\"Check if file should be treated as text.\"\"\"\n    if not path.is_file():\n        return False\n    try:\n        size = path.stat().st_size\n        if size == 0:\n            return path.suffix.lower() in TEXT_EXTS or path.suffix == \"\"\n        if size > MAX_SIZE:\n            return False\n        with path.open(\"rb\") as f:\n            chunk = f.read(min(1024, size))\n        if b\"\\x00\" in chunk:\n            return False\n        chunk.decode(\"utf-8\")\n        return True\n    except (OSError, UnicodeDecodeError, PermissionError):\n        return False\n\n\ndef _translate_globs_to_regex(globs: list[str]) -> list[str]:\n    \"\"\"Translate shell globs to regex strings with normalization.\"\"\"\n    regex_list: list[str] = []\n    for glob_pattern in globs:\n        line = glob_pattern.strip()\n        if not line or line.startswith(\"#\"):\n            continue\n        # fnmatch.translate handles **, *, ?, and char classes\n        regex_list.append(fnmatch.translate(line))\n    return regex_list\n\n\ndef read_paleaeignore(root: Path) -> tuple[list[str], list[str]]:\n    \"\"\"Return (positive_globs, negative_globs) from .paleaeignore.\"\"\"\n    pos: list[str] = []\n    neg: list[str] = []\n    path = root / PALEAEIGNORE\n    if not path.is_file():\n        return pos, neg\n    try:\n        lines = path.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n        for line_item in lines:\n            line = line_item.strip()\n            if not line or line.startswith(\"#\"):\n                continue\n            if line.startswith(\"!\"):\n                neg.append(line[1:].strip())\n            else:\n                pos.append(line)\n    except (OSError, PermissionError):\n        print(f\"Warning: Could not read {PALEAEIGNORE}\", file=sys.stderr)\n    return pos, neg\n\n\ndef compile_patterns(patterns: Optional[list[str]]) -> list[re.Pattern[str]]:\n    \"\"\"Compile regex patterns with error handling.\"\"\"\n    if not patterns:\n        return []\n    compiled = []\n    for pattern in patterns:\n        try:\n            compiled.append(re.compile(pattern))\n        except re.error as e:\n            raise PaleaeError(f\"Invalid regex '{pattern}': {e}\") from e\n    return compiled\n\n\ndef matches_any(text: str, patterns: list[re.Pattern[str]]) -> bool:\n    \"\"\"Check if text matches any pattern.\"\"\"\n    return any(p.search(text) for p in patterns)\n\n\ndef collect_files(\n    root: Path,\n    inc_patterns: list[re.Pattern[str]],\n    exc_patterns: list[re.Pattern[str]],\n    ign_pos_patterns: list[re.Pattern[str]],\n    ign_neg_patterns: list[re.Pattern[str]],\n) -> list[str]:\n    \"\"\"Collect files matching all filter criteria.\"\"\"\n    if not root.is_dir():\n        raise PaleaeError(f\"Directory not found: {root}\")\n\n    files = []\n    try:\n        for path in root.rglob(\"*\"):\n            if not path.is_file():\n                continue\n            try:\n                rel_path = path.relative_to(root).as_posix()\n            except ValueError:\n                continue\n\n            # Step 1: Check if the path is excluded by default, CLI, or .paleaeignore\n            is_excluded = matches_any(rel_path, exc_patterns) or matches_any(\n                rel_path, ign_pos_patterns\n            )\n\n            # Step 2: A negative pattern (!) in .paleaeignore overrides any exclusion\n            if is_excluded and matches_any(rel_path, ign_neg_patterns):\n                is_excluded = False\n\n            if is_excluded:\n                continue\n\n            # Step 3: Check if the path meets the inclusion criteria\n            if inc_patterns and not matches_any(rel_path, inc_patterns):\n                continue\n\n            if is_text_file(path):\n                files.append(rel_path)\n    except (OSError, PermissionError) as e:\n        raise PaleaeError(f\"Error traversing {root}: {e}\") from e\n    return sorted(files)\n\n\ndef build_snapshot(root: Path, rel_files: list[str], ignore_meta: dict[str, Any]) -> dict[str, Any]:\n    \"\"\"Build complete snapshot data, including metadata.\"\"\"\n    files_data, total_chars, total_tokens = [], 0, 0\n    for rel_path in rel_files:\n        full_path = root / rel_path\n        try:\n            content = full_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n            if not content.strip():\n                continue\n        except (OSError, PermissionError, UnicodeDecodeError):\n            continue\n\n        chars = len(content)\n        tokens = token_estimate(content)\n        files_data.append(\n            {\n                \"path\": rel_path,\n                \"content\": content,\n                \"size_chars\": chars,\n                \"sha256\": hashlib.sha256(content.encode(\"utf-8\", errors=\"ignore\")).hexdigest(),\n                \"estimated_tokens\": tokens,\n            }\n        )\n        total_chars += chars\n        total_tokens += tokens\n\n    return {\n        \"meta\": {\n            \"tool\": \"paleae\",\n            \"version\": __version__,\n            \"license\": __license__,\n            \"website\": __website__,\n            \"source\": __source__,\n            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n            \"root_directory\": str(root),\n            \"ignore_file\": ignore_meta,\n            \"summary\": {\n                \"total_files\": len(files_data),\n                \"total_chars\": total_chars,\n                \"estimated_tokens\": total_tokens,\n            },\n        },\n        \"files\": files_data,\n    }\n\n\ndef write_output(path: Path, data: dict[str, Any], format: str) -> None:\n    \"\"\"Write data as JSON or JSONL file.\"\"\"\n    try:\n        path.parent.mkdir(parents=True, exist_ok=True)\n        if format == \"json\":\n            content = json.dumps(data, indent=2, ensure_ascii=False)\n            path.write_text(content, encoding=\"utf-8\")\n        else:  # jsonl\n            with path.open(\"w\", encoding=\"utf-8\") as f:\n                f.write(json.dumps({\"type\": \"meta\", **data[\"meta\"]}, ensure_ascii=False) + \"\\n\")\n                for row in data[\"files\"]:\n                    f.write(json.dumps({\"type\": \"file\", **row}, ensure_ascii=False) + \"\\n\")\n    except (OSError, PermissionError) as e:\n        raise PaleaeError(f\"Error writing {path}: {e}\") from e\n\n\n# --- CLI and Main Execution ---\n\n\ndef create_parser() -> argparse.ArgumentParser:\n    \"\"\"Create CLI argument parser.\"\"\"\n    parser = argparse.ArgumentParser(description=\"Create JSON/JSONL snapshot of your repo for LLMs\")\n    parser.add_argument(\n        \"directory\", nargs=\"?\", default=\".\", help=\"Directory to snapshot (default: .)\"\n    )\n    parser.add_argument(\"-o\", \"--out\", help=\"Output file (auto-named if not specified)\")\n    parser.add_argument(\n        \"-f\", \"--format\", choices=[\"json\", \"jsonl\"], default=\"json\", help=\"Output format\"\n    )\n    parser.add_argument(\n        \"--profile\", choices=list(PROFILES.keys()), default=\"minimal\", help=\"File inclusion profile\"\n    )\n    parser.add_argument(\"--include\", action=\"append\", help=\"Extra include regex (repeatable)\")\n    parser.add_argument(\"--exclude\", action=\"append\", help=\"Extra exclude regex (repeatable)\")\n    parser.add_argument(\"--version\", action=\"version\", version=f\"paleae {__version__}\")\n    parser.add_argument(\"--about\", action=\"store_true\", help=\"Show project info and exit\")\n    return parser\n\n\ndef main() -> int:  # noqa: PLR0911\n    \"\"\"Run the main entry point.\"\"\"\n    parser = create_parser()\n    args = parser.parse_args()\n\n    if args.about:\n        print(\n            f\"paleae {__version__} ({__license__})\\nWebsite: {__website__}\\nSource:  {__source__}\"\n        )\n        return 0\n\n    try:\n        # --- Setup ---\n        root = Path(args.directory).resolve()\n        if not root.is_dir():\n            print(f\"Error: '{args.directory}' is not a directory\", file=sys.stderr)\n            return 1\n\n        # --- Pattern Compilation ---\n        profile = PROFILES.get(args.profile, PROFILES[\"minimal\"])\n        inc_cli = compile_patterns((args.include or []) + profile[\"include\"])\n        exc_cli = compile_patterns((args.exclude or []) + profile[\"exclude\"])\n\n        pos_globs, neg_globs = read_paleaeignore(root)\n        ign_pos_rx = compile_patterns(_translate_globs_to_regex(pos_globs))\n        ign_neg_rx = compile_patterns(_translate_globs_to_regex(neg_globs))\n        ignore_meta = {\n            \"file\": PALEAEIGNORE,\n            \"present\": bool(pos_globs or neg_globs),\n            \"patterns\": len(pos_globs),\n            \"negations\": len(neg_globs),\n        }\n\n        # --- File Collection ---\n        files = collect_files(root, inc_cli, exc_cli, ign_pos_rx, ign_neg_rx)\n        if not files:\n            print(\"No text files found matching criteria.\", file=sys.stderr)\n            return 1\n\n        # --- Snapshot Generation & Output ---\n        data = build_snapshot(root, files, ignore_meta)\n        out_path = Path(args.out) if args.out else Path(f\"repo_snapshot.{args.format}\")\n        write_output(out_path, data, args.format)\n\n        # --- Summary ---\n        s = data[\"meta\"][\"summary\"]\n        print(f\"✓ Snapshot saved to {out_path}\")\n        print(\n            f\"  Files: {s['total_files']}  \"\n            f\"Characters: {s['total_chars']:,}  \"\n            f\"Tokens: {s['estimated_tokens']:,}\"\n        )\n        return 0\n\n    except PaleaeError as e:\n        print(f\"Error: {e}\", file=sys.stderr)\n        return 1\n    except KeyboardInterrupt:\n        print(\"\\nCancelled by user\", file=sys.stderr)\n        return 1\n    except Exception as e:\n        print(f\"Unexpected error: {e}\", file=sys.stderr)\n        return 1\n\n\ndef cli_entrypoint() -> None:\n    \"\"\"Console entry point (kept tiny so tests can patch sys.exit).\"\"\"\n    sys.exit(main())\n\n\nif __name__ == \"__main__\":\n    cli_entrypoint()\n",
      "size_chars": 11833,
      "sha256": "791a58139ccde003b8ca957dfcf5cde63859c532243b0e7cbcd3732a4a57ca03",
      "estimated_tokens": 2958
    }
  ]
}